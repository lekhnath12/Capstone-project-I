{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the accident data from csv\n",
    "violation_df = pd.read_csv('Traffic_Violations-api.csv', \n",
    "                           parse_dates = [['Date Of Stop', 'Time Of Stop']],\n",
    "                           infer_datetime_format = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1384236 entries, 0 to 1384235\n",
      "Data columns (total 34 columns):\n",
      "Date Of Stop_Time Of Stop    1384236 non-null datetime64[ns]\n",
      "Agency                       1384236 non-null object\n",
      "SubAgency                    1384226 non-null object\n",
      "Description                  1384227 non-null object\n",
      "Location                     1384234 non-null object\n",
      "Latitude                     1283334 non-null float64\n",
      "Longitude                    1283334 non-null float64\n",
      "Accident                     1384236 non-null object\n",
      "Belts                        1384236 non-null object\n",
      "Personal Injury              1384236 non-null object\n",
      "Property Damage              1384236 non-null object\n",
      "Fatal                        1384236 non-null object\n",
      "Commercial License           1384236 non-null object\n",
      "HAZMAT                       1384236 non-null object\n",
      "Commercial Vehicle           1384236 non-null object\n",
      "Alcohol                      1384236 non-null object\n",
      "Work Zone                    1384236 non-null object\n",
      "State                        1384177 non-null object\n",
      "VehicleType                  1384236 non-null object\n",
      "Year                         1375769 non-null float64\n",
      "Make                         1384179 non-null object\n",
      "Model                        1384046 non-null object\n",
      "Color                        1367433 non-null object\n",
      "Violation Type               1384236 non-null object\n",
      "Charge                       1384236 non-null object\n",
      "Article                      1314986 non-null object\n",
      "Contributed To Accident      1384236 non-null object\n",
      "Race                         1384236 non-null object\n",
      "Gender                       1384236 non-null object\n",
      "Driver City                  1383956 non-null object\n",
      "Driver State                 1384225 non-null object\n",
      "DL State                     1383307 non-null object\n",
      "Arrest Type                  1384236 non-null object\n",
      "Geolocation                  1283334 non-null object\n",
      "dtypes: datetime64[ns](1), float64(3), object(30)\n",
      "memory usage: 359.1+ MB\n"
     ]
    }
   ],
   "source": [
    "violation_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change the index to datetime\n",
    "violation_df.index = violation_df['Date Of Stop_Time Of Stop']\n",
    "\n",
    "#delete data with Nan\n",
    "viol_df_clean = violation_df.dropna(how = 'any')\n",
    "\n",
    "#This eliminates unncessary and duplicate columns from the data\n",
    "viol_df_clean = viol_df_clean.drop(['Agency','Driver State','State', 'Geolocation',\n",
    "                                  'Driver City','Charge', 'Location'], \n",
    "                                   axis = 1)\n",
    "\n",
    "# transforms the race column into white and non-white\n",
    "race_cate = (viol_df_clean.Race.unique())\n",
    "race_cate = race_cate[race_cate != 'WHITE']\n",
    "\n",
    "viol_df_clean.loc[:,'Race'].replace(to_replace = race_cate, \n",
    "                                    value = 'Non_WHITE', \n",
    "                                    inplace = True)\n",
    "\n",
    "# Transforms the vehicle_list column into auto and non_auto\n",
    "auto_cate = viol_df_clean.VehicleType.unique()\n",
    "auto_cate = auto_cate[auto_cate != '02 - Automobile']\n",
    "\n",
    "viol_df_clean.loc[:, 'VehicleType'].replace(to_replace = auto_cate,\n",
    "                                            value = 'Non-AUTO',\n",
    "                                            inplace = True)\n",
    "\n",
    "\n",
    "# Transforms the DL state into MD and out of state category\n",
    "dl_cate = viol_df_clean['DL State'].unique()\n",
    "dl_cate = dl_cate[dl_cate != 'MD']\n",
    "\n",
    "viol_df_clean.loc[:,'DL State'].replace(to_replace = dl_cate, \n",
    "                                        value = 'Out-ofSTATE',\n",
    "                                        inplace = True)\n",
    "\n",
    "# This selects the columns that are categorical \n",
    "df_categorical = viol_df_clean[['Accident', 'Belts', 'Personal Injury', 'Property Damage', 'Fatal',\n",
    "                                'Commercial License', 'HAZMAT', 'Commercial Vehicle', 'Alcohol',\n",
    "                                'Work Zone', 'VehicleType', 'Violation Type', 'Article',\n",
    "                                'Contributed To Accident','Race', 'Gender', 'DL State']]\n",
    "\n",
    "# copy the categorical columns so that it forgets the origional indices\n",
    "df_cat = df_categorical.copy(deep =  False)\n",
    "\n",
    "# Translate the data into dummy binary\n",
    "df_cat_dumm = pd.get_dummies(df_cat, drop_first = True)\n",
    "\n",
    "# numerical portion of the data \n",
    "df_numerical = viol_df_clean[['Latitude', 'Longitude', 'Year']]\n",
    "\n",
    "# This data can't be converted into binary dummy but still keep it\n",
    "df_none = viol_df_clean[['Description', 'Make', 'Model', 'Color' ]]\n",
    "\n",
    "# combine all the data\n",
    "df_traffic = pd.concat([df_cat_dumm, df_numerical, df_none], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'authorization', 'card', 'control', 'demand', 'device', 'display', 'displaying', 'drive', 'driver', 'exceeding', 'expired', 'fail', 'handheld', 'hands', 'highway', 'hwy', 'individual', 'instructions', 'issued', 'lamps', 'license', 'lighted', 'limit', 'line', 'maximum', 'motion', 'motor', 'mph', 'o', 'obey', 'officer', 'person', 'placed', 'plate', 'plates', 'police', 'posted', 'privilege', 'properly', 'property', 'public', 'rear', 'reasonable', 'red', 'registration', 'required', 'right', 'sign', 'signal', 'speed', 'state', 'stop', 'suspended', 'telephone', 'traffic', 'uniformed', 'use', 'using', 'veh', 'w', 'whilemotor', 'zone']\n"
     ]
    }
   ],
   "source": [
    "# The description column is full of text. We vectorize the test so that we can fit it into the model. \n",
    "corpus = df_traffic.Description\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english', \n",
    "                             strip_accents = 'ascii', \n",
    "                             min_df = 0.025, \n",
    "                             max_features = 100,\n",
    "                             token_pattern='[a-z]+',\n",
    "                             max_df = 0.25,\n",
    "                             binary  = True)\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "\"\"\"This translates text in each column as a vector array of following basis (keywords)\"\"\"\n",
    "\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The description data in the form of 2D-array of vectors\n",
    "X3 = X[:].toarray()\n",
    "\n",
    "feature = vectorizer.get_feature_names()\n",
    "\n",
    "#convert the text data into a DataFrame\n",
    "col_list = ['desc_'+ st for st in feature]\n",
    "df_desc = pd.DataFrame(list(X3), columns= col_list)\n",
    "df_desc.index = df_traffic.index\n",
    "\n",
    "# combine two DataFrames\n",
    "df = pd.concat([df_traffic, df_desc], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save dataframe as CSV\n",
    "df.to_csv('data_wrangled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
